{"pageProps":{"postData":{"id":6,"title":"Асинхронность вместе с многопоточностью в Python","text":"Большинство современных веб-приложений завязаны на вводе и выводе данных, по типу `ЗАПРОС -> ОТВЕТ`. И только относительно небольшая часть нуждается в сложной обработке данных, где требуется максимально использовать всю мощь процессора.\r\nКогда вы пишете асинхроннй код на Python, весь код выполняется в одном потоке и этот поток переключается на различные события, например обрабатывает новый запрос пока делается долгий запрос в базу данных.\r\n\r\nНо что делать если хочется в разы увеличить производительность сервера и задействовать не используемые ядра CPU? Для этого в Python есть модуль Multiprocessing он на каждом ядре запускает интерпретатор Python, что позволяет одновременно запустить не сколько экземпляров программы и увеличить скорость ее работы. Если ещё хочется эффективно обрабатывать IO операции и выжать максимум производительности стоит объединить Multiprocessing и Asyncio.\r\n\r\nВ данном случае мы создадим несколько процессов и внутри каждого будет создан свой цикл событий (event loop), созданные циклы событий будут делать асинхронные запросы для получения данных. \r\n\r\nВзаимодействие мужду процессами будет происходить с помощью:\r\n\r\n✔️ `multiprocessing.JoinableQueue()` для создания процессов.\r\n\r\n✔️ `multiprocessing.Queue()` для результатов, чтобы мы могли узнать количество успешных запросов на скачивание. \r\n\r\n```    \r\nfail_count = sum(\r\n    1 for _ in range(amount_pages) if 'failed' in result_queue.get()\r\n)\r\nlogger.info(\r\n    f'Done, success: {amount_pages - fail_count}/{amount_pages}, '\r\n    f'failure: {fail_count}/{amount_pages}'\r\n)\r\n```\r\n\r\nКаждый созданный объект очереди в функции `main` мы передаём в `Image(task_queue, result_queue, url, out_dir, args.mode, item))`.\r\n```\r\ntask_queue = multiprocessing.JoinableQueue()\r\n    result_queue = multiprocessing.Queue()\r\n    if process_count < multiprocessing.cpu_count():\r\n        process_count = multiprocessing.cpu_count()\r\n    logger.info(f'Spawning {process_count} gatherers...')\r\n\r\n    images = [\r\n        Image(task_queue, result_queue, url, out_dir, args.mode, item)\r\n        for _ in range(process_count)\r\n    ]\r\n```\r\nКласс `Image` наследуется от `multiprocessing.Process` поэтому у мы можем вызвать у него метод start.\r\n```\r\nfor image in images:\r\n    image.start()\r\n```\r\nДалее в методе `run` определяем каким образом запускать наш парсер, синхронно или асинхронно. Из файла настроек `settings.yaml` берём количество страниц необходимое для загрузки. И через очередь распределяем их по процессам, например первый процесс получит страницы [1, 2] второй [3, 4], третий [5].\r\n\r\nВ целом работа с многопоточностью и асинхронностью не слишком отличается от написания однопоточного асинхронного кода, основное отличие это необходимость использования очередей для того, чтобы основной процесс знал когда все задачи будут выполнены. \r\nДля лучшего понимания поизучайте работу кода. \r\nРежимы запуска:\r\n```\r\n-m, --mode\r\n    async or sync\r\n-p, --process\r\n    количество процессов\r\n```\r\n\r\n```Синхронный режим с 6 процессами `python image_scraper.py -m sync -p 6```\r\n```Асинхронный режим с 8 процессами `python image_scraper.py -m async -p 8```\r\n\r\nЕсли хотите использовать дебагер `pdb` можете использовать такую конструкцию:\r\n```\r\nimport sys\r\nimport pdb\r\n\r\nclass ForkedPdb(pdb.Pdb):\r\n    \"\"\"A Pdb subclass that may be used\r\n    from a forked multiprocessing child\r\n\r\n    \"\"\"\r\n    def interaction(self, *args, **kwargs):\r\n        _stdin = sys.stdin\r\n        try:\r\n            sys.stdin = open('/dev/stdin')\r\n            pdb.Pdb.interaction(self, *args, **kwargs)\r\n        finally:\r\n            sys.stdin = _stdin\r\n```\r\nИ в коде добавьте `ForkedPdb().set_trace()`.  \r\nВесь код можно посмотреть: https://github.com/Random1k11/multyproc_asyncio","image":"http://d-rusanov.ru/media/python-snake_3T5z8pw.jpeg","active":true,"updated_at":"2021-02-13T20:27:39.010653+03:00","created_at":"2021-02-12T22:04:25.940018+03:00","slug":"asyncio-with-multiprocessing","categories":[]}},"__N_SSG":true}